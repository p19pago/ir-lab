{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36462ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted Indexing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c167c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DocIDDoc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cd6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDID = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93720a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1\t ./shakespeare\\A Midsummer Nigh\n",
      "Midsummer Night's Dream: Entire Play\n",
      "['Midsummer', \"Night's\", 'Dream:', 'Entire', 'Play']\n",
      "\n",
      "[]\n",
      "A Midsummer Night's Dream\n",
      "['A', 'Midsummer', \"Night's\", 'Dream']\n",
      "  2\t ./shakespeare\\All's Well That \n",
      "All's Well That Ends Well: Entire Play\n",
      "[\"All's\", 'Well', 'That', 'Ends', 'Well:', 'Entire', 'Play']\n",
      "\n",
      "[]\n",
      "All's Well That Ends Well\n",
      "[\"All's\", 'Well', 'That', 'Ends', 'Well']\n",
      "  3\t ./shakespeare\\Antony and Cleop\n",
      "Antony and Cleopatra: Entire Play\n",
      "['Antony', 'and', 'Cleopatra:', 'Entire', 'Play']\n",
      "\n",
      "[]\n",
      "Antony and Cleopatra\n",
      "['Antony', 'and', 'Cleopatra']\n",
      "  4\t ./shakespeare\\As You Like It  \n",
      "As You Like It: Entire Play\n",
      "['As', 'You', 'Like', 'It:', 'Entire', 'Play']\n",
      "\n",
      "[]\n",
      "As You Like It\n",
      "['As', 'You', 'Like', 'It']\n",
      "  5\t ./shakespeare\\Coriolanus      \n",
      "  6\t ./shakespeare\\Cymbeline       \n",
      "  7\t ./shakespeare\\Hamlet          \n",
      "  8\t ./shakespeare\\Henry IV, part 1\n",
      "  9\t ./shakespeare\\Henry IV, part 2\n",
      " 10\t ./shakespeare\\Henry V         \n",
      " 11\t ./shakespeare\\Henry VI, part 1\n",
      " 12\t ./shakespeare\\Henry VI, part 2\n",
      " 13\t ./shakespeare\\Henry VI, part 3\n",
      " 14\t ./shakespeare\\Henry VIII      \n",
      " 15\t ./shakespeare\\Julius Caesar   \n",
      " 16\t ./shakespeare\\King John       \n",
      " 17\t ./shakespeare\\King Lear       \n",
      " 18\t ./shakespeare\\Love's Labours L\n",
      " 19\t ./shakespeare\\Macbeth         \n",
      " 20\t ./shakespeare\\Measure for Meas\n",
      " 21\t ./shakespeare\\Much Ado About N\n",
      " 22\t ./shakespeare\\Othello         \n",
      " 23\t ./shakespeare\\Pericles, Prince\n",
      " 24\t ./shakespeare\\Richard II      \n",
      " 25\t ./shakespeare\\Richard III     \n",
      " 26\t ./shakespeare\\Romeo and Juliet\n",
      " 27\t ./shakespeare\\Taming of the Sh\n",
      " 28\t ./shakespeare\\The Comedy of Er\n",
      " 29\t ./shakespeare\\The Merchant of \n",
      " 30\t ./shakespeare\\The Tempest     \n",
      " 31\t ./shakespeare\\TheMerry Wives o\n",
      " 32\t ./shakespeare\\Timon of Athens \n",
      " 33\t ./shakespeare\\Titus Andronicus\n",
      " 34\t ./shakespeare\\Troilus and Cres\n",
      " 35\t ./shakespeare\\Twelfth Night   \n",
      " 36\t ./shakespeare\\Two Gentlemen of\n",
      " 37\t ./shakespeare\\Winter's Tale   \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "maxDocID = 0\n",
    "skip_symbols = \"!\\\"'#$%&()*+-,./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "for f in glob.glob(\"./shakespeare/*.txt\"):\n",
    "    maxDocID += 1\n",
    "    playName = f.replace('./shakespeare/','').replace('.txt','')\n",
    "    DocIDDoc[maxDocID] = playName\n",
    "    print('{0:3d}\\t'.format(maxDocID), '{0: <30}'.format(playName[0:30]))\n",
    "    with open(f) as file:\n",
    "        l = 1\n",
    "        for line in file:\n",
    "            line_as_str = line.rstrip()\n",
    "            line_tokens = line_as_str.split()\n",
    "            l += 1\n",
    "            if maxDocID<5 and l < 5: \n",
    "                print( line_as_str )\n",
    "                print( line_tokens )\n",
    "            for token in line_tokens:\n",
    "                for s in skip_symbols:\n",
    "                    token = token.replace(s, '')\n",
    "                if len(token)>0:\n",
    "                # if skip_symbols.find(token) == -1: \n",
    "                    TDID.append((token, maxDocID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84f9695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Nights', 1), ('Dream', 1), ('Entire', 1), ('Play', 1), ('A', 1), ('Midsummer', 1), ('Nights', 1), ('Dream', 1), ('Shakespeare', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(TDID[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55bada03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8\n",
      "1 8\n",
      "1 11\n",
      "1 11\n",
      "1 14\n",
      "10 14\n",
      "2 9\n",
      "2 9\n",
      "2 12\n",
      "2 12\n",
      "2 14\n",
      "2d 8\n",
      "2s 8\n",
      "2s 8\n",
      "3 13\n",
      "3 13\n",
      "3 14\n",
      "4 14\n",
      "4d 8\n",
      "5 14\n",
      "5s 8\n",
      "6 14\n",
      "6d 8\n",
      "7 14\n",
      "8 14\n",
      "8d 8\n",
      "9 14\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n",
      "A 1\n"
     ]
    }
   ],
   "source": [
    "TDID.sort(key=lambda tpl: tpl[0])\n",
    "i = 0\n",
    "for (token, DocID) in TDID:\n",
    "    print(token, DocID)\n",
    "    i += 1\n",
    "    if i >= 50:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38a1e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {8, 11, 14}\n",
      "10 {14}\n",
      "2 {9, 12, 14}\n",
      "2d {8}\n",
      "2s {8}\n",
      "3 {13, 14}\n",
      "4 {14}\n",
      "4d {8}\n",
      "5 {14}\n",
      "5s {8}\n",
      "6 {14}\n",
      "6d {8}\n",
      "7 {14}\n",
      "8 {14}\n",
      "8d {8}\n",
      "9 {14}\n",
      "A {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37}\n",
      "AARON {33}\n",
      "ABERGAVENNY {14}\n",
      "ABHORSON {20}\n"
     ]
    }
   ],
   "source": [
    "TDIDsets = {}\n",
    "for token, DocID in TDID:\n",
    "    if token in TDIDsets:\n",
    "        TDIDsets[token].add(DocID)\n",
    "    else:\n",
    "        TDIDsets[token] = {DocID}\n",
    "\n",
    "i = 0\n",
    "for token in TDIDsets.keys():\n",
    "    print(token, TDIDsets[token])\n",
    "    i += 1\n",
    "    if i >= 20:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cb8d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                              [  3] =>\t [8, 11, 14]\n",
      "10                             [  1] =>\t [14]\n",
      "2                              [  3] =>\t [9, 12, 14]\n",
      "2d                             [  1] =>\t [8]\n",
      "2s                             [  1] =>\t [8]\n",
      "3                              [  2] =>\t [13, 14]\n",
      "4                              [  1] =>\t [14]\n",
      "4d                             [  1] =>\t [8]\n",
      "5                              [  1] =>\t [14]\n",
      "5s                             [  1] =>\t [8]\n",
      "6                              [  1] =>\t [14]\n",
      "6d                             [  1] =>\t [8]\n",
      "7                              [  1] =>\t [14]\n",
      "8                              [  1] =>\t [14]\n",
      "8d                             [  1] =>\t [8]\n",
      "9                              [  1] =>\t [14]\n",
      "A                              [ 37] =>\t [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "AARON                          [  1] =>\t [33]\n",
      "ABERGAVENNY                    [  1] =>\t [14]\n",
      "ABHORSON                       [  1] =>\t [20]\n",
      "ABRAHAM                        [  1] =>\t [26]\n",
      "ACHILLES                       [  1] =>\t [34]\n",
      "ACT                            [ 37] =>\t [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n",
      "ADAM                           [  1] =>\t [4]\n",
      "ADRIAN                         [  1] =>\t [30]\n",
      "ADRIANA                        [  1] =>\t [28]\n",
      "ADRIANO                        [  1] =>\t [18]\n",
      "AEGEON                         [  1] =>\t [28]\n",
      "AEMELIA                        [  1] =>\t [28]\n",
      "AEMILIA                        [  1] =>\t [28]\n",
      "AEMILIUS                       [  1] =>\t [33]\n",
      "AENEAS                         [  1] =>\t [34]\n",
      "AEacida                        [  1] =>\t [12]\n",
      "AEacides                       [  1] =>\t [27]\n",
      "AEdile                         [  1] =>\t [5]\n",
      "AEdiles                        [  1] =>\t [5]\n",
      "AEgeon                         [  1] =>\t [28]\n",
      "AEgle                          [  1] =>\t [1]\n",
      "AEmilia                        [  1] =>\t [28]\n",
      "AEmilius                       [  1] =>\t [33]\n",
      "AEneas                         [  5] =>\t [3, 12, 30, 33, 34]\n",
      "AEneastake                     [  1] =>\t [34]\n",
      "AEolus                         [  1] =>\t [12]\n",
      "AEsculapius                    [  2] =>\t [23, 31]\n",
      "AEson                          [  1] =>\t [29]\n",
      "AEsop                          [  1] =>\t [13]\n",
      "AEtna                          [  1] =>\t [33]\n",
      "AGAMEMNON                      [  1] =>\t [34]\n",
      "AGRIPPA                        [  2] =>\t [3, 5]\n",
      "AGUECHEEK                      [  1] =>\t [35]\n"
     ]
    }
   ],
   "source": [
    "InvertedIndex = {}\n",
    "\n",
    "i = 0\n",
    "for token in TDIDsets.keys():\n",
    "    InvertedIndex[token] = sorted(list(TDIDsets[token]))\n",
    "    \n",
    "    i += 1\n",
    "    if i <= 50:\n",
    "        print('{0: <30}'.format(token[0:30]), '[{0:3d}] =>\\t'.format(len(InvertedIndex[token])), InvertedIndex[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec37281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase function - as text we'll use an extract from \"Romeo and Juliet\" as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5be6101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two households, both alike in dignity, in fair verona, where we lay our scene, from ancient grudge break to new mutiny, where civil blood makes civil hands unclean.\n"
     ]
    }
   ],
   "source": [
    "text = \"Two households, both alike in dignity, In fair Verona, where we lay our scene, From ancient grudge break to new mutiny, Where civil blood makes civil hands unclean.\"\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8756422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra whitespaces function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f03dfcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Καλημέραπαίδες\n"
     ]
    }
   ],
   "source": [
    "text = \"Two households, both alike in dignity, In fair Verona, where we lay our scene, From ancient grudge break to new mutiny, Where civil blood makes civil hands unclean.\"\n",
    "print(text.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d949409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b18e6c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'households', ',', 'both', 'alike', 'in', 'dignity', ',', 'in', 'fair', 'verona', ',', 'where', 'we', 'lay', 'our', 'scene', ',', 'from', 'ancient', 'grudge', 'break', 'to', 'new', 'mutiny', ',', 'where', 'civil', 'blood', 'makes', 'civil', 'hands', 'unclean', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59dc109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation removal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b7788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "765d7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two households both alike in dignity in fair verona where we lay our scene from ancient grudge break to new mutiny where civil blood makes civil hands unclean\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cf814f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae93e331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'households', ',', 'alike', 'dignity', ',', 'fair', 'verona', ',', 'lay', 'scene', ',', 'ancient', 'grudge', 'break', 'new', 'mutiny', ',', 'civil', 'blood', 'makes', 'civil', 'hands', 'unclean', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0b0454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b52b95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'household', ',', 'alik', 'digniti', ',', 'fair', 'verona', ',', 'lay', 'scene', ',', 'ancient', 'grudg', 'break', 'new', 'mutini', ',', 'civil', 'blood', 'make', 'civil', 'hand', 'unclean', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in filtered_words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38b90cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9e5474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip\n",
      "stripe\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"stripes\", 'v')) #verb\n",
    "print(lemmatizer.lemmatize(\"stripes\", 'n')) #noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44383825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
